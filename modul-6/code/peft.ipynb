{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af9f200",
   "metadata": {},
   "source": [
    "### **Inisialisasi**\n",
    "\n",
    "Seperti fine tuning model lainnya kita harus menentukan model backbone yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85edd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Nama model yang ingin di-fine-tune\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# Load model dan tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fc9d7",
   "metadata": {},
   "source": [
    "### **LoRA**\n",
    "\n",
    "#### **Rank (r)**\n",
    "Rank dari matriks dekomposisi A dan B. Ini adalah parameter paling krusial dalam LoRA karena secara langsung mengontrol jumlah parameter yang dapat dilatih. Kegunaannya adalah menentukan \"kapasitas\" atau kompleksitas dari adaptasi yang dapat dipelajari oleh model.\n",
    "Cara kerjanya:\n",
    "- Nilai r kecil (misal, 4, 8, 16): Menghasilkan matriks A dan B yang sangat kecil. Jumlah parameter yang dilatih sedikit, proses fine-tuning lebih cepat, dan kebutuhan memori lebih rendah. Ini cocok untuk adaptasi tugas yang tidak terlalu kompleks.\n",
    "- Nilai r besar (misal, 64, 128, 256): Menghasilkan matriks A dan B yang lebih besar. Model memiliki kapasitas lebih untuk mempelajari adaptasi yang kompleks, namun dengan biaya komputasi dan memori yang lebih tinggi.\n",
    "\n",
    "#### **LoRA Alpha**\n",
    "\n",
    "Kegunaan: Mengontrol seberapa besar \"magnitudo\" atau pengaruh dari matriks adaptasi LoRA terhadap output asli dari lapisan pre-trained. Ini mirip dengan learning rate, tetapi berlaku untuk seluruh matriks adaptasi.\n",
    "Bagaimana cara kerjanya:\n",
    "Ketika lora_alpha diatur sama dengan r (misalnya lora_alpha=16 dan r=16), penskalaannya menjadi 1, yang berarti tidak ada penskalaan tambahan.\n",
    "Mengatur lora_alpha lebih tinggi dari r (misalnya lora_alpha=32 dan r=16) akan memperkuat pengaruh dari adaptasi LoRA.\n",
    "\n",
    "#### **LoRA Dropout**\n",
    "Ini adalah dropout rate yang diterapkan pada matriks adaptasi LoRA (biasanya pada matriks B).\n",
    "Kegunaannya adalah sebagai teknik regulasi untuk mencegah overfitting pada parameter-parameter LoRA yang sedang dilatih.\n",
    "Cara kerjanya: Selama proses pelatihan, sebagian neuron (unit) dari matriks adaptasi akan dinonaktifkan secara acak pada setiap iterasi. Ini memaksa model untuk tidak terlalu bergantung pada beberapa parameter adaptasi saja, sehingga meningkatkan kemampuannya untuk generalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rank dari matriks adaptasi rendah\n",
    "    lora_alpha=32, # Skala untuk matriks adaptasi\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # Jenis task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapkan model untuk pelatihan 8-bit dan tambahkan adapter LoRA\n",
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a60b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definisikan argumen pelatihan\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    output_dir=\"./lora_fine_tuned_model\",\n",
    "    fp16=True,\n",
    "    push_to_hub=False # Set ke True jika ingin menyimpan ke Hugging Face Hub\n",
    ")\n",
    "\n",
    "# Definisikan trainer SFT (Supervised Fine-Tuning)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data, # Ganti dengan dataset Anda\n",
    "    args=training_arguments,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\" # Sesuaikan dengan nama kolom teks di dataset Anda\n",
    ")\n",
    "\n",
    "# Latih model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan adapter LoRA\n",
    "trainer.save_model(\"./lora_adapters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f9bb6",
   "metadata": {},
   "source": [
    "### **QLoRA dengan Unsloth**\n",
    "\n",
    "QLoRA atau Quantized Low Rank Adaptation adalah teknik PEFT yang mirip dengan LoRA namun kita fine tuning dengan kuantisasi model LLM ke byte yang lebih kecil seperti 16 bit, 8 bit hingga int 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-0.6B\",\n",
    "    max_seq_length = 2048,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = True,     # quantized to 4-bit, uses less memory\n",
    "    load_in_8bit = False,    # quantized to 8-bit, uses less memory\n",
    "    full_finetuning = False, # full finetuning?\n",
    "    # token = \"hf_...\",     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "reasoning_dataset = load_dataset(\"unsloth/OpenMathReasoning-mini\", split = \"cot\")\n",
    "non_reasoning_dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f877fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation(examples):\n",
    "    problems  = examples[\"problem\"]\n",
    "    solutions = examples[\"generated_solution\"]\n",
    "    conversations = []\n",
    "    for problem, solution in zip(problems, solutions):\n",
    "        conversations.append([\n",
    "            {\"role\" : \"user\",      \"content\" : problem},\n",
    "            {\"role\" : \"assistant\", \"content\" : solution},\n",
    "        ])\n",
    "    return { \"conversations\": conversations, }\n",
    "\n",
    "reasoning_conversations = tokenizer.apply_chat_template(\n",
    "    reasoning_dataset.map(generate_conversation, batched = True)[\"conversations\"],\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2485ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "dataset = standardize_sharegpt(non_reasoning_dataset)\n",
    "\n",
    "non_reasoning_conversations = tokenizer.apply_chat_template(\n",
    "    dataset[\"conversations\"],\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chat_percentage = 0.25\n",
    "non_reasoning_subset = pd.Series(non_reasoning_conversations)\n",
    "non_reasoning_subset = non_reasoning_subset.sample(\n",
    "    int(len(reasoning_conversations)*(chat_percentage/(1 - chat_percentage))),\n",
    "    random_state = 2407,\n",
    ")\n",
    "print(len(reasoning_conversations))\n",
    "print(len(non_reasoning_subset))\n",
    "print(len(non_reasoning_subset) / (len(non_reasoning_subset) + len(reasoning_conversations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "    pd.Series(reasoning_conversations),\n",
    "    pd.Series(non_reasoning_subset)\n",
    "])\n",
    "data.name = \"text\"\n",
    "\n",
    "from datasets import Dataset\n",
    "combined_dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "combined_dataset = combined_dataset.shuffle(seed = 3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ca69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = combined_dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
